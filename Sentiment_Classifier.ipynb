{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Sentiment_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0Nte8dpyJp"
      },
      "source": [
        "The first 3 code cells of this notebook are related to using Google Colab. This first cell gives Colab access to my Google Drive contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3iGDffpplXO",
        "outputId": "8a6958d3-5760-4e8a-d4d4-f32679fbd8c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZAc-gyIp7Ol"
      },
      "source": [
        "I'm changing the current directory to the directory of this notebook in my Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL69KA3RpzT2"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5e62pHzqFjR"
      },
      "source": [
        "Colab doesn't have the transformers package installed so this will install it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1qwdufxFoxz",
        "outputId": "f5642da6-33ae-408a-9f5b-ca6ad0d8b085"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Wv8QKiFaQm"
      },
      "source": [
        "from nltk.tree import Tree\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWpxFCSEoYle"
      },
      "source": [
        "Here is a link to the data. Unzip it into the same directory as this notebook.\n",
        "\n",
        "https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip\n",
        "\n",
        "The data is in a tree format with 5 categories of sentiment. The following function reads in the data and flattens each tree into a string. It also reduces the 5 categories to just 2 (postive and negative)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LvRjaxXFaQ_"
      },
      "source": [
        "def sentiment_treebank_reader(filename):\n",
        "    with open(filename, encoding='utf8') as f:\n",
        "        X, y = [], []\n",
        "        for line in f:\n",
        "            tree = Tree.fromstring(line)\n",
        "            label = int(tree.label())\n",
        "            string = \" \".join(tree.leaves())\n",
        "\n",
        "            if label == 0 or label == 1: \n",
        "                y.append(0)\n",
        "                X.append(string)\n",
        "                \n",
        "            elif label == 3 or label == 4:\n",
        "                y.append(1)\n",
        "                X.append(string)\n",
        "    return X, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loD5HyuOFaRA"
      },
      "source": [
        "X_str_dev, y_dev = sentiment_treebank_reader('trees/dev.txt')\n",
        "X_str_train, y_train = sentiment_treebank_reader('trees/train.txt')\n",
        "X_str_test, y_test = sentiment_treebank_reader('trees/test.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dGWqR8atfoH"
      },
      "source": [
        "We now define a dataset class in which the data consists of Bert-tokenized versions of the string data we just read in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf2IVqAxFaRB"
      },
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, strings, labels):\n",
        "        self.strings = strings\n",
        "        self.labels = labels\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        string = self.strings[index]\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        encoding = self.tokenizer.encode_plus(string, \n",
        "                    add_special_tokens=True, return_attention_mask=True, padding='max_length')\n",
        "        return (\n",
        "                torch.tensor(encoding['input_ids']).to(device), \n",
        "                torch.tensor(encoding['attention_mask']).to(device), \n",
        "                torch.tensor(label, dtype=torch.long).to(device)\n",
        "        )\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.strings)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A80WZfWhFaRB"
      },
      "source": [
        "train_set = SentimentDataset(X_str_train, y_train)\n",
        "dev_set = SentimentDataset(X_str_dev, y_dev)\n",
        "test_set = SentimentDataset(X_str_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16)\n",
        "dev_loader = DataLoader(dev_set, batch_size=16)\n",
        "test_loader = DataLoader(test_set, batch_size=16)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckg0hVVQuRKM"
      },
      "source": [
        "As in the paper, the model is Bert with a classifier on the [CLS] output. We will then fine-tune the entire model on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqP5ePcFaRC"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.classifier_layer = nn.Linear(768, 2)\n",
        "    \n",
        "    def forward(self, indices, mask):\n",
        "        cls_output = self.bert(indices, attention_mask=mask)['pooler_output']\n",
        "        return self.classifier_layer(cls_output)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVm2EP5sFaRC"
      },
      "source": [
        "model = SentimentClassifier()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zG-E-iSuyGZ"
      },
      "source": [
        "This helper function evaluates the loss and accuracy on a given dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a3KUePGfIVo"
      },
      "source": [
        "def evaluate_model(model, data_loader, criterion, length):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        for inputs, masks, labels in data_loader:\n",
        "            outputs = model(inputs, masks)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss, correct_predictions.item() / length"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyG_ZIuYzwue"
      },
      "source": [
        "Here is the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA1R3JHRFaRC",
        "outputId": "60f56b8e-534c-4585-b938-1ed4c118f213"
      },
      "source": [
        "# best_accuracy = 0\n",
        "for epoch in range(2):\n",
        "    print('Epoch', epoch + 1)\n",
        "    model.train()\n",
        "\n",
        "    for inputs, masks, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, masks)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss, train_acc = evaluate_model(model, train_loader, criterion, len(train_set))\n",
        "    dev_loss, dev_acc = evaluate_model(model, dev_loader, criterion, len(dev_set))\n",
        "    print('Train loss', train_loss, '  accuracy', train_acc)\n",
        "    print('Dev   loss', dev_loss, '  accuracy', dev_acc)\n",
        "\n",
        "    # if dev_acc > best_accuracy:\n",
        "    #     torch.save(model.state_dict(), 'best_model.bin')\n",
        "    #     best_accuracy = dev_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo51305YC1Eh"
      },
      "source": [
        "# model = SentimentClassifier()\n",
        "# model.load_state_dict(torch.load('best_model.bin'))\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj9BuVtGgGOk"
      },
      "source": [
        "_, test_acc = evaluate_model(model, test_loader, criterion, len(test_set))\n",
        "print('Test accuracy', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}